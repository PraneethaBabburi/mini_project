{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mdk-Fv7QET51"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 24 23:41:56 2020\n",
    "\n",
    "@author: rajku\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, precision_recall_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Model_Evaluation:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def ROC_Curve_Generator(self, df, no_of_output, offset):\n",
    "\n",
    "        for x in range(no_of_output):\n",
    "            plt.figure()\n",
    "            # plot no skill roc curve\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n",
    "            # calculate roc curve for model\n",
    "            fpr, tpr, _ = roc_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "            # plot model roc curve\n",
    "            plt.plot(fpr, tpr, marker='.', label='ROC_DNN_' + df.columns[x])\n",
    "            # axis labels\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            # show the legend\n",
    "            plt.legend()\n",
    "            # show the plot\n",
    "            plt.show()\n",
    "\n",
    "    def ROC_Curve_Generator_Subplot(self, df, no_of_output, offset):\n",
    "\n",
    "        fig, a = plt.subplots(1, 3, squeeze=False, figsize=(18, 4))\n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
    "\n",
    "        for x in range(no_of_output):\n",
    "            # plot no skill roc curve\n",
    "            a[0, x].plot([0, 1], [0, 1], linestyle='--', label='No_Skill_' + df.columns[x])\n",
    "            # calculate roc curve for model\n",
    "            fpr, tpr, _ = roc_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "            # plot model roc curve\n",
    "            a[0, x].plot(fpr, tpr, marker='.', label='ROC_' + df.columns[x])\n",
    "            # axis labels\n",
    "            a[0, x].set_xlabel('False Positive Rate', fontsize=15)\n",
    "            a[0, x].set_ylabel('True Positive Rate', fontsize=15)\n",
    "            # show the legend\n",
    "            a[0, x].legend(fontsize=15)\n",
    "            a[0, x].text(0.6, 0.4, \"AUC = \" + \"{:.2f}\".format(\n",
    "                round(roc_auc_score(df.iloc[:, x], df.iloc[:, x + (offset * 2)]), 2)), transform=a[0, x].transAxes,\n",
    "                         fontsize=14, verticalalignment='top', bbox=props)\n",
    "            a[0, x].text(0.5, -0.3, \"(\" + string.ascii_lowercase[x] + \")\", transform=a[0, x].transAxes, size=20)\n",
    "\n",
    "        filename = 'results/ROC_AUC_Curve_' + str(no_of_output) + '.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    def ROC_Curve_Generator_Subplot_Comparison(self, df, df_SVM, df_LSTM, no_of_output, offset):\n",
    "\n",
    "        fig, a = plt.subplots(1, 3, squeeze=False, figsize=(18, 4))\n",
    "\n",
    "        for x in range(no_of_output):\n",
    "            # plot no skill roc curve\n",
    "            # a[0, x].plot([0, 1], [0, 1], linestyle='--', label='No_Skill_' + df.columns[x])\n",
    "            # calculate roc curve for model\n",
    "            fpr, tpr, _ = roc_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "            # plot model roc curve\n",
    "            a[0, x].plot(fpr, tpr, marker='.', label='ROC_' + df.columns[x] + '_DNN')\n",
    "\n",
    "            # calculate roc curve for model\n",
    "            fpr_SVC, tpr_SVC, _ = roc_curve(df_SVM.iloc[:, x], df_SVM.iloc[:, x + offset])\n",
    "            # plot model roc curve\n",
    "            a[0, x].plot(fpr_SVC, tpr_SVC, marker='.', label='ROC_' + df.columns[x] + '_SVM')\n",
    "\n",
    "            # calculate roc curve for model\n",
    "            fpr_LSTM, tpr_LSTM, _ = roc_curve(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + offset])\n",
    "            # plot model roc curve\n",
    "            a[0, x].plot(fpr_LSTM, tpr_LSTM, marker='.', label='ROC_' + df.columns[x] + '_LSTM')\n",
    "\n",
    "            # axis labels\n",
    "            a[0, x].set_xlabel('False Positive Rate', fontsize=15)\n",
    "            a[0, x].set_ylabel('True Positive Rate', fontsize=15)\n",
    "            # show the legend\n",
    "            a[0, x].legend(fontsize=12)\n",
    "            a[0, x].text(0.55, 0.65, \"AUC_DNN = \" + \"{:.2f}\".format(\n",
    "                round(roc_auc_score(df.iloc[:, x], df.iloc[:, x + (offset * 2)]), 2)), transform=a[0, x].transAxes,\n",
    "                         fontsize=14, verticalalignment='top')  # , bbox=props)\n",
    "            a[0, x].text(0.55, 0.55, \"AUC_SVM = \" + \"{:.2f}\".format(\n",
    "                round(roc_auc_score(df_SVM.iloc[:, x], df_SVM.iloc[:, x + (offset * 2)]), 2)),\n",
    "                         transform=a[0, x].transAxes, fontsize=14, verticalalignment='top')  # , bbox=props)\n",
    "            a[0, x].text(0.55, 0.45, \"AUC_LSTM = \" + \"{:.2f}\".format(\n",
    "                round(roc_auc_score(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + (offset * 2)]), 2)),\n",
    "                         transform=a[0, x].transAxes, fontsize=14, verticalalignment='top')  # , bbox=props)\n",
    "\n",
    "            a[0, x].text(0.5, -0.3, \"(\" + string.ascii_lowercase[x] + \")\", transform=a[0, x].transAxes, size=20)\n",
    "\n",
    "        filename = 'results/ROC_AUC_Curve_' + str(no_of_output) + '.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    def PR_Curve_Generator(self, df, no_of_output, offset, no_skill_df, nsd_offset):\n",
    "        for x in range(no_of_output):\n",
    "            print(\n",
    "                f'Average Precision Score for {df.columns[x]} is {average_precision_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "\n",
    "            plt.figure()\n",
    "\n",
    "            y = no_skill_df.iloc[:, x + nsd_offset]\n",
    "            no_skill = len(y[y == 1]) / len(y)\n",
    "            # plot the no skill precision-recall curve\n",
    "            plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "            # plot the model precision-recall curve\n",
    "            plt.plot(recall, precision, marker='.', label='PR_DNN_' + df.columns[x])\n",
    "            # axis labels\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            # show the legend\n",
    "            plt.legend()\n",
    "            # show the plot\n",
    "            plt.show()\n",
    "\n",
    "    def PR_Curve_Generator_Subplot(self, df, no_of_output, offset, no_skill_df, nsd_offset):\n",
    "        fig, a = plt.subplots(1, 3, squeeze=False, figsize=(18, 4))\n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
    "        for x in range(no_of_output):\n",
    "            print(\n",
    "                f'Average Precision Score for {df.columns[x]} is {average_precision_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "\n",
    "            y = no_skill_df.iloc[:, x + nsd_offset]\n",
    "            no_skill = len(y[y == 1]) / len(y)\n",
    "            # plot the no skill precision-recall curve\n",
    "            a[0, x].plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "            # plot the model precision-recall curve\n",
    "            a[0, x].plot(recall, precision, marker='.', label='PR_DNN_' + df.columns[x])\n",
    "            # axis labels\n",
    "            a[0, x].set_xlabel('Recall', fontsize=15)\n",
    "            a[0, x].set_ylabel('Precision', fontsize=15)\n",
    "            # show the legend\n",
    "            a[0, x].legend(fontsize=13)\n",
    "\n",
    "            a[0, x].text(0.1, 0.3, \"Average Precision = \" + \"{:.2f}\".format(\n",
    "                round(average_precision_score(df.iloc[:, x], df.iloc[:, x + offset]), 2)), transform=a[0, x].transAxes,\n",
    "                         fontsize=14, verticalalignment='top', bbox=props)\n",
    "            a[0, x].text(0.5, -0.3, \"(\" + string.ascii_lowercase[x] + \")\", transform=a[0, x].transAxes, size=20)\n",
    "\n",
    "        filename = 'results/PR_Curve_' + str(no_of_output) + '.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    def PR_Curve_Generator_Subplot_Comparison(self, df, df_SVM, df_LSTM, no_of_output, offset, no_skill_df, nsd_offset):\n",
    "        fig, a = plt.subplots(1, 3, squeeze=False, figsize=(18, 4))\n",
    "\n",
    "        for x in range(no_of_output):\n",
    "            print(\n",
    "                f'Average Precision Score for {df.columns[x]} is {average_precision_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "            # plot the model precision-recall curve\n",
    "            a[0, x].plot(recall, precision, marker='.', label='PR_' + df.columns[x] + '_DNN')\n",
    "\n",
    "            precision_SVC, recall_SVC, _ = precision_recall_curve(df_SVM.iloc[:, x], df_SVM.iloc[:, x + offset])\n",
    "            a[0, x].plot(recall_SVC, precision_SVC, marker='.', label='PR_' + df.columns[x] + '_SVM')\n",
    "\n",
    "            precision_LSTM, recall_LSTM, _ = precision_recall_curve(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + offset])\n",
    "            a[0, x].plot(recall_LSTM, precision_LSTM, marker='.', label='PR_' + df.columns[x] + '_LSTM')\n",
    "\n",
    "            # axis labels\n",
    "            a[0, x].set_xlabel('Recall', fontsize=15)\n",
    "            a[0, x].set_ylabel('Precision', fontsize=15)\n",
    "            # show the legend\n",
    "            a[0, x].legend(fontsize=12, loc='lower right')\n",
    "\n",
    "            a[0, x].set_xlim(0.01, 1.0)\n",
    "            a[0, x].set_ylim(-0.1, 1.0)\n",
    "\n",
    "            a[0, x].text(0.05, 0.58, \"Average Precision (DNN) = \" + \"{:.2f}\".format(\n",
    "                round(average_precision_score(df.iloc[:, x], df.iloc[:, x + offset]), 2)), transform=a[0, x].transAxes,\n",
    "                         fontsize=12, verticalalignment='top')  # bbox=props)\n",
    "            a[0, x].text(0.05, 0.49, \"Average Precision (SVM) = \" + \"{:.2f}\".format(\n",
    "                round(average_precision_score(df_SVM.iloc[:, x], df_SVM.iloc[:, x + offset]), 2)),\n",
    "                         transform=a[0, x].transAxes, fontsize=12, verticalalignment='top')  # , bbox=props)\n",
    "            a[0, x].text(0.05, 0.40, \"Average Precision (LSTM) = \" + \"{:.2f}\".format(\n",
    "                round(average_precision_score(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + offset]), 2)),\n",
    "                         transform=a[0, x].transAxes, fontsize=12, verticalalignment='top')  # , bbox=props)\n",
    "\n",
    "            a[0, x].text(0.5, -0.3, \"(\" + string.ascii_lowercase[x] + \")\", transform=a[0, x].transAxes, size=20)\n",
    "\n",
    "        filename = 'results/PR_Curve_' + str(no_of_output) + '.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    def metrics_printer(self, df, no_of_output, offset):\n",
    "        for x in range(no_of_output):\n",
    "            print(f'Accuracy Score for {df.columns[x]} is {accuracy_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "            print(f'Precision Score for {df.columns[x]} is {precision_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "            print(f'Recall Score for {df.columns[x]} is {recall_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "            print(f'F1 Score for {df.columns[x]} is {f1_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "            print(\n",
    "                f'Cohen Kappa Score for {df.columns[x]} is {cohen_kappa_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "            print(f'ROC AUC Score for {df.columns[x]} is {roc_auc_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "            print(f'Confusion Matrix for {df.columns[x]} is {confusion_matrix(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "\n",
    "    def metrics_file_writer(self, file_name, df, no_of_output, offset):\n",
    "        with open(file_name, 'w') as f:\n",
    "            for x in range(no_of_output):\n",
    "                print(f'Accuracy Score for {df.columns[x]} is {accuracy_score(df.iloc[:, x], df.iloc[:, x + offset])}',\n",
    "                      file=f)\n",
    "                print(\n",
    "                    f'Precision Score for {df.columns[x]} is {precision_score(df.iloc[:, x], df.iloc[:, x + offset])}',\n",
    "                    file=f)\n",
    "                print(f'Recall Score for {df.columns[x]} is {recall_score(df.iloc[:, x], df.iloc[:, x + offset])}',\n",
    "                      file=f)\n",
    "                print(f'F1 Score for {df.columns[x]} is {f1_score(df.iloc[:, x], df.iloc[:, x + offset])}', file=f)\n",
    "                print(\n",
    "                    f'Cohen Kappa Score for {df.columns[x]} is {cohen_kappa_score(df.iloc[:, x], df.iloc[:, x + offset])}',\n",
    "                    file=f)\n",
    "                print(f'ROC AUC Score for {df.columns[x]} is {roc_auc_score(df.iloc[:, x], df.iloc[:, x + offset])}',\n",
    "                      file=f)\n",
    "                print(\n",
    "                    f'Confusion Matrix for {df.columns[x]} is {confusion_matrix(df.iloc[:, x], df.iloc[:, x + offset])}',\n",
    "                    file=f)\n",
    "\n",
    "    def figure_generator_single_output(self, df, no_of_output, offset, no_skill_df, nsd_offset):\n",
    "        fig, a = plt.subplots(1, 2, squeeze=False, figsize=(18, 4))\n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
    "\n",
    "        x = 0\n",
    "\n",
    "        # plot no skill roc curve\n",
    "        a[0, 0].plot([0, 1], [0, 1], linestyle='--', label='No_Skill_' + df.columns[x])\n",
    "        # calculate roc curve for model\n",
    "        fpr, tpr, _ = roc_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "        # plot model roc curve\n",
    "        a[0, 0].plot(fpr, tpr, marker='.', label='ROC_' + df.columns[x])\n",
    "        # axis labels\n",
    "        a[0, 0].set_xlabel('False Positive Rate', fontsize=15)\n",
    "        a[0, 0].set_ylabel('True Positive Rate', fontsize=15)\n",
    "        # show the legend\n",
    "        a[0, 0].legend(fontsize=15)\n",
    "        a[0, 0].text(0.6, 0.4,\n",
    "                     \"AUC = \" + \"{:.2f}\".format(round(roc_auc_score(df.iloc[:, x], df.iloc[:, x + (offset * 2)]), 2)),\n",
    "                     transform=a[0, 0].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "        a[0, 0].text(0.5, -0.3, \"(\" + string.ascii_lowercase[x] + \")\", transform=a[0, 0].transAxes, size=20)\n",
    "        a[0, 0].set_xlim(-0.004, 1.0)\n",
    "        a[0, 0].set_ylim(-0.01, 1.01)\n",
    "\n",
    "        print(\n",
    "            f'Average Precision Score for {df.columns[x]} is {average_precision_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "\n",
    "        y = no_skill_df.iloc[:, x + nsd_offset]\n",
    "        no_skill = len(y[y == 1]) / len(y)\n",
    "        # plot the no skill precision-recall curve\n",
    "        a[0, 1].plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "        # plot the model precision-recall curve\n",
    "        a[0, 1].plot(recall, precision, marker='.', label='PR_DNN_' + df.columns[x])\n",
    "        # axis labels\n",
    "        a[0, 1].set_xlabel('Recall', fontsize=15)\n",
    "        a[0, 1].set_ylabel('Precision', fontsize=15)\n",
    "        # show the legend\n",
    "        a[0, 1].legend(fontsize=13)\n",
    "\n",
    "        a[0, 1].set_xlim(0.0, 1.0)\n",
    "        a[0, 1].set_ylim(0.4, 1.01)\n",
    "\n",
    "        a[0, 1].text(0.1, 0.3, \"Average Precision = \" + \"{:.2f}\".format(\n",
    "            round(average_precision_score(df.iloc[:, x], df.iloc[:, x + offset]), 2)), transform=a[0, 1].transAxes,\n",
    "                     fontsize=14, verticalalignment='top', bbox=props)\n",
    "        a[0, 1].text(0.5, -0.3, \"(\" + string.ascii_lowercase[1] + \")\", transform=a[0, 1].transAxes, size=20)\n",
    "\n",
    "        filename = 'results/ROC_PR_Curve_' + str(no_of_output) + '.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    def figure_generator_single_output_comparison(self, df, df_SVM, df_LSTM, no_of_output, offset, no_skill_df,\n",
    "                                                  nsd_offset):\n",
    "        fig, a = plt.subplots(1, 2, squeeze=False, figsize=(18, 4))\n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
    "\n",
    "        x = 0\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "        # plot model roc curve\n",
    "        a[0, 0].plot(fpr, tpr, marker='.', label='ROC_DNN')\n",
    "        # axis labels\n",
    "\n",
    "        fpr_SVM, tpr_SVM, _ = roc_curve(df_SVM.iloc[:, x], df_SVM.iloc[:, x + offset])\n",
    "        # plot model roc curve\n",
    "        a[0, 0].plot(fpr_SVM, tpr_SVM, marker='.', label='ROC_SVM')\n",
    "\n",
    "        fpr_LSTM, tpr_LSTM, _ = roc_curve(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + offset])\n",
    "        # plot model roc curve\n",
    "        a[0, 0].plot(fpr_LSTM, tpr_LSTM, marker='.', label='ROC_LSTM')\n",
    "\n",
    "        # axis labels\n",
    "\n",
    "        a[0, 0].set_xlabel('False Positive Rate', fontsize=15)\n",
    "        a[0, 0].set_ylabel('True Positive Rate', fontsize=15)\n",
    "        # show the legend\n",
    "        a[0, 0].legend(fontsize=15)\n",
    "        a[0, 0].text(0.6, 0.5, \"AUC_DNN = \" + \"{:.2f}\".format(\n",
    "            round(roc_auc_score(df.iloc[:, x], df.iloc[:, x + (offset * 2)]), 2)), transform=a[0, 0].transAxes,\n",
    "                     fontsize=14, verticalalignment='top', bbox=props)\n",
    "        a[0, 0].text(0.6, 0.4, \"AUC_SVM = \" + \"{:.2f}\".format(\n",
    "            round(roc_auc_score(df_SVM.iloc[:, x], df_SVM.iloc[:, x + (offset * 2)]), 2)), transform=a[0, 0].transAxes,\n",
    "                     fontsize=14, verticalalignment='top', bbox=props)\n",
    "        a[0, 0].text(0.6, 0.3, \"AUC_LSTM = \" + \"{:.2f}\".format(\n",
    "            round(roc_auc_score(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + (offset * 2)]), 2)),\n",
    "                     transform=a[0, 0].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "\n",
    "        a[0, 0].text(0.5, -0.3, \"(\" + string.ascii_lowercase[x] + \")\", transform=a[0, 0].transAxes, size=20)\n",
    "\n",
    "        a[0, 0].set_xlim(-0.004, 1.0)\n",
    "        a[0, 0].set_ylim(-0.01, 1.01)\n",
    "\n",
    "        print(\n",
    "            f'Average Precision Score for {df.columns[x]} is {average_precision_score(df.iloc[:, x], df.iloc[:, x + offset])}')\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(df.iloc[:, x], df.iloc[:, x + offset])\n",
    "        # plot the model precision-recall curve\n",
    "        a[0, 1].plot(recall, precision, marker='.', label='PR_DNN')\n",
    "\n",
    "        precision_SVM, recall_SVM, _ = precision_recall_curve(df_SVM.iloc[:, x], df_SVM.iloc[:, x + offset])\n",
    "        # plot the model precision-recall curve\n",
    "        a[0, 1].plot(recall_SVM, precision_SVM, marker='.', label='PR_SVM')\n",
    "\n",
    "        precision_LSTM, recall_LSTM, _ = precision_recall_curve(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + offset])\n",
    "        # plot the model precision-recall curve\n",
    "        a[0, 1].plot(recall_LSTM, precision_LSTM, marker='.', label='PR_LSTM')\n",
    "\n",
    "        # axis labels\n",
    "        a[0, 1].set_xlabel('Recall', fontsize=15)\n",
    "        a[0, 1].set_ylabel('Precision', fontsize=15)\n",
    "        # show the legend\n",
    "        a[0, 1].legend(fontsize=13)\n",
    "\n",
    "        a[0, 1].set_xlim(0.05, 1.0)\n",
    "        a[0, 1].set_ylim(0.0, 1.01)\n",
    "\n",
    "        a[0, 1].text(0.4, 0.4, \"Average Precision (DNN) = \" + \"{:.2f}\".format(\n",
    "            round(average_precision_score(df.iloc[:, x], df.iloc[:, x + offset]), 2)), transform=a[0, 1].transAxes,\n",
    "                     fontsize=14, verticalalignment='top', bbox=props)\n",
    "        a[0, 1].text(0.4, 0.3, \"Average Precision (SVM) = \" + \"{:.2f}\".format(\n",
    "            round(average_precision_score(df_SVM.iloc[:, x], df_SVM.iloc[:, x + offset]), 2)),\n",
    "                     transform=a[0, 1].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "        a[0, 1].text(0.4, 0.2, \"Average Precision (LSTM) = \" + \"{:.2f}\".format(\n",
    "            round(average_precision_score(df_LSTM.iloc[:, x], df_LSTM.iloc[:, x + offset]), 2)),\n",
    "                     transform=a[0, 1].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "\n",
    "        a[0, 1].text(0.5, -0.3, \"(\" + string.ascii_lowercase[1] + \")\", transform=a[0, 1].transAxes, size=20)\n",
    "\n",
    "        filename = 'results/ROC_PR_Curve_' + str(no_of_output) + '.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    def box_plot_generator(self, df, columns, df_car, columns_car):\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, squeeze=False, figsize=(24, 4))\n",
    "        flierprops = dict(marker='o', markerfacecolor=\"0.5\", markersize=3,\n",
    "                          linestyle='none', markeredgecolor=\"0.5\")\n",
    "\n",
    "        ax = (df[columns]).boxplot(by=columns[0], ax=axes.flatten()[0], fontsize=15, grid=False, widths=0.3,\n",
    "                                   flierprops=flierprops)\n",
    "        ax.axhline(y=0.5, color=\"0.5\", linestyle='--', alpha=0.5)\n",
    "        ax.set_xlabel('Non-Trustworthy (0) and Trustworthy(1)', fontsize=12)\n",
    "        ax.set_ylabel('Predicted Trustworthiness Scores', fontsize=12)\n",
    "        ax.set_title('')\n",
    "        fig = np.asarray(ax).reshape(-1)[0].get_figure()\n",
    "        fig.suptitle('', fontsize=1)\n",
    "        ax.text(0.5, -0.3, \"(\" + string.ascii_lowercase[0] + \")\", transform=ax.transAxes, size=20)\n",
    "\n",
    "        ax_C = (1 - df_car[[columns_car[0], columns_car[3]]]).boxplot(by=columns_car[0], ax=axes.flatten()[1],\n",
    "                                                                      fontsize=15, grid=False, widths=0.3,\n",
    "                                                                      flierprops=flierprops)\n",
    "        ax_C.axhline(y=0.5, color=\"0.5\", linestyle='--', alpha=0.5)\n",
    "        ax_C.set_xlabel('Non-Trustworthy (0) and Trustworthy(1)', fontsize=12)\n",
    "        ax_C.set_ylabel('Predicted Trustworthiness Scores', fontsize=12)\n",
    "        ax_C.set_title('')\n",
    "        fig = np.asarray(ax_C).reshape(-1)[0].get_figure()\n",
    "        fig.suptitle('', fontsize=1)\n",
    "        ax_C.text(0.5, -0.3, \"(\" + string.ascii_lowercase[1] + \")\", transform=ax_C.transAxes, size=20)\n",
    "\n",
    "        ax_L = (1 - df_car[[columns_car[1], columns_car[4]]]).boxplot(by=columns_car[1], ax=axes.flatten()[2],\n",
    "                                                                      fontsize=15, grid=False, widths=0.3,\n",
    "                                                                      flierprops=flierprops)\n",
    "        ax_L.axhline(y=0.5, color=\"0.5\", linestyle='--', alpha=0.5)\n",
    "        ax_L.set_xlabel('Non-Trustworthy (0) and Trustworthy(1)', fontsize=12)\n",
    "        ax_L.set_ylabel('Predicted Trustworthiness Scores', fontsize=12)\n",
    "        ax_L.set_title('')\n",
    "        fig = np.asarray(ax_L).reshape(-1)[0].get_figure()\n",
    "        fig.suptitle('', fontsize=1)\n",
    "        ax_L.text(0.5, -0.3, \"(\" + string.ascii_lowercase[2] + \")\", transform=ax_L.transAxes, size=20)\n",
    "\n",
    "        ax_R = (1 - df_car[[columns_car[2], columns_car[5]]]).boxplot(by=columns_car[2], ax=axes.flatten()[3],\n",
    "                                                                      fontsize=15, grid=False, widths=0.3,\n",
    "                                                                      flierprops=flierprops)\n",
    "        ax_R.axhline(y=0.5, color=\"0.5\", linestyle='--', alpha=0.5)\n",
    "        ax_R.set_xlabel('Non-Trustworthy (0) and Trustworthy(1)', fontsize=12)\n",
    "        ax_R.set_ylabel('Predicted Trustworthiness Scores', fontsize=12)\n",
    "        ax_R.set_title('')\n",
    "        fig = np.asarray(ax_R).reshape(-1)[0].get_figure()\n",
    "        fig.suptitle('', fontsize=1)\n",
    "        ax_R.text(0.5, -0.3, \"(\" + string.ascii_lowercase[3] + \")\", transform=ax_R.transAxes, size=20)\n",
    "\n",
    "        filename = 'results/Box_Plot_All.png'\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches='tight', figsize=(9, 11))\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
